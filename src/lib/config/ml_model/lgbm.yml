name: LightGBM
description: 'LightGBM is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages: Faster training speed and higher efficiency, Lower memory usage, Better accuracy, Support of parallel and GPU learning, Capable of handling large-scale data.'
hyperparameters:
    n_estimators:
        value: 100
        description: 'Number of boosting rounds'
        type: integer
    learning_rate:
        value: 0.1
        description: 'Boosting learning rate'
        type: float
    subsample:
        value: 1.0
        description: 'Subsample ratio of the training instance (alias for bagging_fraction)'
        type: float
    colsample_bytree:
        value: 1.0
        description: 'Subsample ratio of columns when constructing each tree (alias for feature_fraction)'
        type: float
    num_leaves:
        value: 31
        description: 'Maximum number of leaves in one tree'
        type: integer
    min_child_samples:
        value: 20
        description: 'Minimum number of data needed in a child (leaf)'
        type: integer
    min_child_weight:
        value: 0.001
        description: 'Minimum sum hessian in one leaf'
        type: float
    reg_alpha:
        value: 0.0
        description: 'L1 regularization term on weights'
        type: float
    reg_lambda:
        value: 0.0
        description: 'L2 regularization term on weights'
        type: float
parameters:
    max_depth:
        value: -1
        description: 'Maximum tree depth for base learners, <=0 means no limit'
        type: integer
    objective:
        value:
            default: 'regression'
            options:
                regression: 'Regression task'
                binary: 'Binary classification task'
                multiclass: 'Multiclass classification task'
        description: 'Type of task'
        type: string
optuna_grid:
    n_estimators:
        low: 100
        high: 1000
        type: integer
    num_leaves:
        low: 2
        high: 256
        type: integer
    learning_rate:
        low: 1e-3
        high: 1.0
        log: true
        type: float
    subsample:
        low: 0.5
        high: 1.0
        type: float
    colsample_bytree:
        low: 0.5
        high: 1.0
        type: float
    min_child_samples:
        low: 5
        high: 100
        type: integer
    # max_depth:
    #     low: 1
    #     high: 10
    #     type: integer
    # min_child_weight:
    #     low: 1
    #     high: 10
    #     type: integer
    # reg_alpha:
    #     low: 1e-8
    #     high: 10.0
    #     log: true
    #     type: float
    # reg_lambda:
    #     low: 1e-8
    #     high: 10.0
    #     log: true
    #     type: float
    # bagging_freq:
    #     low: 1
    #     high: 7
    #     type: integer
# NOTES:
# bagging_fraction  = alias for subsample
# bagging_freq = alias for subsample_freq
# feature_fraction = alias for colsample_bytree
